{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b9cba8b-37d9-4dcf-ac29-3afc47098eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractclassmethod\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections.abc import Callable, Iterable\n",
    "from dataclasses import dataclass, field\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from random import random, shuffle\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics as stats\n",
    "\n",
    "from tqdm import tqdm\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d9971d3-20f5-4ca3-ac53-0f40c8d22a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path: str) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Loads every csv file in the path.\"\"\"\n",
    "    dataloader = {file_path.split(\"/\")[-1].split(\".\")[0]: pd.read_csv(file_path, header=None, sep=\" \") for file_path in glob(path+\"*.csv\")}\n",
    "    return dataloader\n",
    "\n",
    "@dataclass\n",
    "class Model(ABC):\n",
    "    \"\"\"Base Representation of a Machine Learning Model.\"\"\"\n",
    "    loss: Optional[Callable[[np.ndarray, np.ndarray], np.ndarray]]\n",
    "    optimizer: Optional[Callable[[np.ndarray, np.ndarray, np.ndarray,], (np.ndarray, float)]]\n",
    "    hist: Dict[str, List]\n",
    "    learning_rate: float \n",
    "    epochs: int\n",
    "    eval_step: int\n",
    "    early_stop: bool\n",
    "    range_flag: bool\n",
    "    \n",
    "    @abstractclassmethod\n",
    "    def predict(self, X: np.ndarray) -> None:\n",
    "        \"\"\"Predicts the out come of Matrix X.\"\"\"\n",
    "        pass\n",
    "        \n",
    "    @abstractclassmethod\n",
    "    def update_weights(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"Updates the weights of the model after one step or epoch.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractclassmethod\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray ) -> None:\n",
    "        \"\"\"trains the model using the vector features X and labels Y.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractclassmethod\n",
    "    def save_hist(self, X: np.ndarray, y: np.ndarray, i: int) -> None:\n",
    "        \"\"\"Saves the parameters of the model in between updates of training.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def plot_training(self) -> go.Figure:\n",
    "        \"\"\"Animate the change of prediction of the model on training data with dimension of 1.\"\"\"\n",
    "        assert self.range_flag == False\n",
    "        fig=go.Figure().set_subplots(1,1, vertical_spacing=0.05,\n",
    "                             specs=[[{\"type\": \"scatter\", \"secondary_y\": False}]])\n",
    "        \n",
    "        # first frame of the plot\n",
    "        fig.add_trace(go.Scatter(x=self.hist[\"x_range\"], y=self.hist[\"y_range\"], name=\"train\", mode='markers'), 1,1)\n",
    "        fig.add_trace(go.Scatter(x=self.hist[\"x_range\"], y=self.hist[\"y_range\"], name=\"train\", mode='markers'), 1,1);\n",
    "\n",
    "        fig.update(frames=self.hist[\"frame\"])\n",
    "        \n",
    "        # details about the plot layout\n",
    "        sliders_dict = {\"active\": 0, \"yanchor\": \"top\", \"xanchor\": \"left\",\n",
    "                        \"currentvalue\": { \"font\": {\"size\": 20}, \"prefix\": \"Year:\", \"visible\": True, \"xanchor\": \"right\"},\n",
    "                        \"transition\": {\"duration\": 300, \"easing\": \"cubic-in-out\"}, \"pad\": {\"b\": 10, \"t\": 50}, \"len\": 0.9, \n",
    "                        \"x\": 0.1, \"y\": 0, \"steps\": []}\n",
    "\n",
    "        updatemenus_dict = {\n",
    "                \"buttons\": [{\"args\": [None, {\"frame\": {\"duration\": 500, \"redraw\": False}, \"fromcurrent\": True,\n",
    "                \"transition\": {\"duration\": 300, \"easing\": \"quadratic-in-out\"}}], \"label\": \"Play\", \"method\": \"animate\"},\n",
    "                {\"args\": [[None], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\", \"transition\": {\"duration\": 0}}],\n",
    "                \"label\": \"Pause\", \"method\": \"animate\"}], \"direction\": \"left\", \"pad\": {\"r\": 10, \"t\": 87}, \"showactive\": True,\n",
    "                \"type\": \"buttons\", \"x\": 0.1, \"xanchor\": \"right\", \"y\": 0, \"yanchor\": \"top\",\n",
    "                }\n",
    "\n",
    "        fig.update_layout(sliders=[sliders_dict],\n",
    "                          updatemenus = [updatemenus_dict])\n",
    "\n",
    "        return fig\n",
    "    \n",
    "    def plot_history(self, keys: Iterable) -> go.Figure:\n",
    "        \"\"\"Plots the keys saved in self.hist for each epoch.\"\"\"\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "        for key in keys:\n",
    "            fig.add_trace(go.Scatter(x=np.arange(stop=self.epochs,),\n",
    "                                     y=self.hist[key], name=key))\n",
    "        return fig\n",
    "\n",
    "    \n",
    "class Scaler():\n",
    "    mean: float\n",
    "    std: float\n",
    "    def set_standard_scaler(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Standardize features by removing the mean and scaling to unit variance and save it for prediction time.\"\"\"\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        self.std = np.std(X, axis=0)\n",
    "        standard = (X - self.mean) / self.std\n",
    "\n",
    "        return standard\n",
    "\n",
    "    def get_standard_scaler(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Standardize features by removing the mean of training set and scaling to unit variance of training set.\"\"\"\n",
    "        standard = (X - self.mean) / self.std\n",
    "\n",
    "        return standard\n",
    "\n",
    "@dataclass\n",
    "class Layer(ABC):\n",
    "    input_size: int\n",
    "    output_size: int\n",
    "\n",
    "    @abstractclassmethod\n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"computes feed forward of Layer respect to input X\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractclassmethod\n",
    "    def backward_propagation(self, pred, learning_rate):\n",
    "        \"\"\"computes backward propagation of Layer respect to input X\"\"\"\n",
    "        pass\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class FCLayer(Layer):\n",
    "    input_size: int\n",
    "    output_size: int\n",
    "    activation: Callable[[np.ndarray], np.ndarray]\n",
    "    activation_prime: Callable[[np.ndarray], np.ndarray]\n",
    "    \n",
    "    def random_initializers(self, std=1e-4) -> None:\n",
    "        \"\"\"Make a random start for weights and bias\"\"\"\n",
    "        self.weights = std * np.random.randn(self.input_size, self.output_size)\n",
    "        self.bias =  np.zeros((1, self.output_size))\n",
    "\n",
    "    def feed_forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"computes feed forward of Layer respect to input X\"\"\"\n",
    "        # print(f\"W.T={self.weights.T.shape}, x.T={x.T.shape}, b= {self.bias.shape}\")\n",
    "        self.x = x.copy()\n",
    "        self.z =  np.dot(x,self.weights)  + self.bias\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a\n",
    "        \n",
    "    def backward_propagation(self, next_layer_error: np.ndarray) -> (np.ndarray, np.ndarray, np.ndarray):\n",
    "        \"\"\"computes backward propagation of Layer respect to input X\"\"\"\n",
    "        # print(f\"output.shape= {next_layer_error.shape}\")\n",
    "        db = self.activation_prime(self.a) * next_layer_error\n",
    "        # print(f\"error= {error.shape}, W.T= {self.weights.T.shape}\")\n",
    "        output =  np.dot(db, self.weights.T)\n",
    "        # print(f\"x.T={self.x.T.shape}, error= {error.shape}\")\n",
    "        dW = np.dot(self.x.T, db)\n",
    "\n",
    "        return dW, db, output\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class MLP(Model):\n",
    "    \"\"\"Simple MLP Impelementation\"\"\"\n",
    "    layers: List[Layer]\n",
    "    loss_prime: Callable[[np.ndarray], np.ndarray]\n",
    "    \n",
    "    def zero_grads(self) -> None:\n",
    "        for layer in self.layers:\n",
    "            layer.x= 0\n",
    "            layer.z= 0\n",
    "    \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        output = x\n",
    "        for layer in self.layers:\n",
    "            output = layer.feed_forward(output)\n",
    "        return output\n",
    "    \n",
    "    def backward(self, y: float) -> (List[float], List[float]):\n",
    "        output = y\n",
    "        dW, db = [], []\n",
    "        for layer in self.layers[::-1]:\n",
    "            output = layer.backward_propagation(output)\n",
    "            dW.append(output[0])\n",
    "            db.append(output[1])\n",
    "            output = output[2]\n",
    "            \n",
    "        return dW, db\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> List[float]:\n",
    "        \"\"\"Predicts the out come of Matrix X.\"\"\"\n",
    "        preds = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            preds.append(self.forward(X[i]))\n",
    "\n",
    "        return preds\n",
    "        \n",
    "    def update_weights(self, dW: List[float], db: List[float]) -> None:\n",
    "        \"\"\"Updates the weights of the model after one step or epoch.\"\"\"\n",
    "\n",
    "        # print(f\"#layers= {len(self.layers)}, #weights_error:{len(weights_error)}, #error:{len(error)}\")\n",
    "        for i, layer in enumerate(self.layers[::-1]):\n",
    "            # print(f\"dW[{i}] = {dW[i]}, db[{i}] = {db[i]}\")\n",
    "            layer.weights = layer.weights - (self.learning_rate * dW[i])\n",
    "            layer.bias = layer.bias - (self.learning_rate * db[i])\n",
    "            \n",
    "    def random_initializers(self) -> None:\n",
    "        \"\"\"Make a random start for weights and bias\"\"\"\n",
    "        [layer.random_initializers() for layer in self.layers]\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray ) -> None:\n",
    "        \"\"\"trains the model using the vector features X and labels Y.\"\"\"\n",
    "        self.hist={\"weights\":[],\"bias\":[],\"loss\":[0], \"frame\":[]}\n",
    "        # random start\n",
    "        self.random_initializers()\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            loss= 0\n",
    "            # for each sample in training set feed-forward and backpropagate\n",
    "            for i, x in enumerate(X):\n",
    "                self.zero_grads()\n",
    "                # feed-forward\n",
    "                # x = X[i].reshape((X[i].shape[0], 1))\n",
    "                # print(f\"X[i].shape:{x.shape}\")\n",
    "                pred = self.forward(x)\n",
    "                # add loss \n",
    "                loss+= self.loss(y[i], pred)\n",
    "                # compute gradient update\n",
    "                error = self.loss_prime(y[i], pred)\n",
    "                # backward propagation\n",
    "                dW, db = self.backward(error)\n",
    "                # update weights\n",
    "                self.update_weights(dW= dW, db= db)\n",
    "            \n",
    "            # save epoch train history\n",
    "            self.save_hist(X= X, y= y, i= epoch, loss= loss)\n",
    "            if self.hist[\"loss\"][-1] > self.hist[\"loss\"][-2] and self.early_stop:\n",
    "                break\n",
    "\n",
    "    def save_hist(self, X: np.ndarray, y: np.ndarray, i: int, loss: float,) -> None:\n",
    "        \"\"\"Saves the parameters of the model in between updates of training.\"\"\"\n",
    "        self.hist[\"loss\"].append(loss/X.shape[0])\n",
    "        self.hist[\"bias\"].append([layer.bias for layer in self.layers])\n",
    "        self.hist[\"weights\"].append([layer.weights for layer in self.layers])\n",
    "        print(f'Training Loss for epoch {i}: {self.hist[\"loss\"][-1]}')\n",
    "        \n",
    "        if X.shape[1] == 1:\n",
    "            if self.range_flag:\n",
    "                self.hist[\"x_range\"] = [min(X), max(X)]\n",
    "                self.hist[\"y_range\"] = [min(y), max(y)]\n",
    "                self.range_flag = False\n",
    "\n",
    "            if i % self.eval_step == 0:\n",
    "                y_pred = self.predict(X)\n",
    "                print(f'eval Loss for epoch {i}: {sum(self.loss(y_j, y_pred[j]) for j, y_j in enumerate(y))/y.shape[0]}')\n",
    "                \n",
    "                self.hist[\"frame\"].append(go.Frame(data=[go.Scatter(x=X, y=y, name=\"train\", mode='markers'),\n",
    "                                                    go.Scatter(x=X, y=y_pred, name=\"predict\", mode='markers')]))\n",
    "                \n",
    "def plot(plot_points: Iterable[Tuple[np.ndarray, np.ndarray, str]]) -> go.Figure:\n",
    "    \"\"\"Ploting all the (X, y, plot_name) on the same figure.\"\"\"\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "    for X, y, name in plot_points:\n",
    "        fig.add_trace(go.Scatter(x=X, y=y, name=name, mode='markers'))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c779a70-840b-4e5a-9883-af25ff745b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "traindata",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          -40.22844191504942,
          121.19952850885748,
          144.96172544023025,
          -53.60851723261297,
          -80.78260692663481,
          71.86365061491081,
          71.46606200269252,
          -33.32518392345632,
          59.76170064071336,
          -17.71062849254889,
          -65.76873196539196,
          62.63940131898096,
          147.20992236711493,
          -11.802772177150052,
          43.96258946303781,
          -62.873106114089694,
          34.48496286551095,
          -50.94208322766583,
          -84.97715046471542,
          36.848159665703086,
          111.3695965022725,
          47.6487061159283,
          -0.09318746097468825,
          155.07843035271813,
          -37.31162587011175,
          -43.56909367306709,
          -42.212063180048965,
          72.05311045043112,
          57.94525965229457,
          47.802883472549794,
          -108.45603006941228,
          -37.358951406265206,
          -73.88924992755689,
          119.22921289759348,
          -105.96355076448256,
          107.13981775423224,
          73.87107420299392,
          138.87088623981313,
          -113.68897764193548,
          -72.55125003067819,
          145.34507920261996,
          -16.70255290513367,
          -24.168599096551084,
          -147.078116997524,
          102.94747917578634,
          13.68473739451218,
          12.847576475351495,
          -132.79641557565756,
          1.8860982974116547,
          27.1429981169738,
          5.157902013059672,
          -92.6084191604145,
          71.3230421502013,
          47.8679216790956,
          54.23228398138326,
          129.4458088465893,
          42.04992952987218,
          56.219463133367306,
          35.13054353387116,
          -43.80398048653765,
          1.995322656804564,
          -23.082101202665275,
          -68.79265216251946,
          65.45173847935665,
          -55.65121556268075,
          66.31663203773941,
          -50.15216840709069,
          20.33784411960476,
          117.8120950703883,
          -59.942744441061535,
          84.01445024244846,
          0.8589794622610386,
          -49.218442824810495,
          106.25148078477824,
          134.89849745645716,
          -115.875779070194,
          42.33389724045077,
          -70.4754911430795,
          -52.75181513404491,
          160.16900121190633,
          28.718375042976497,
          45.18520883792053,
          16.942337786719616,
          48.55083011712384,
          13.581619287641354,
          64.81342685110238,
          51.25694372869946,
          -92.85526496367903,
          -51.688566640204314,
          13.98689931493217,
          10.110839768323723,
          -112.6863029943036,
          -106.14505006269908,
          -9.678435441999309,
          -15.39672756986158,
          -77.41805720935075,
          15.978143008552935,
          -87.89705332470005,
          -22.137208364626545,
          -60.48862631037337
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          -5.891514806378132,
          104.89151480637813
         ],
         "type": "linear"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          -172.4334617041275,
          185.52434591850982
         ],
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"e8c4aec3-9580-4812-97d8-ddaa5c37f50f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e8c4aec3-9580-4812-97d8-ddaa5c37f50f\")) {                    Plotly.newPlot(                        \"e8c4aec3-9580-4812-97d8-ddaa5c37f50f\",                        [{\"mode\":\"markers\",\"name\":\"traindata\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[-40.22844191504942,121.19952850885748,144.96172544023025,-53.60851723261297,-80.78260692663481,71.86365061491081,71.46606200269252,-33.32518392345632,59.76170064071336,-17.71062849254889,-65.76873196539196,62.63940131898096,147.20992236711493,-11.802772177150052,43.96258946303781,-62.873106114089694,34.48496286551095,-50.94208322766583,-84.97715046471542,36.848159665703086,111.3695965022725,47.6487061159283,-0.09318746097468825,155.07843035271813,-37.31162587011175,-43.56909367306709,-42.212063180048965,72.05311045043112,57.94525965229457,47.802883472549794,-108.45603006941228,-37.358951406265206,-73.88924992755689,119.22921289759348,-105.96355076448256,107.13981775423224,73.87107420299392,138.87088623981313,-113.68897764193548,-72.55125003067819,145.34507920261996,-16.70255290513367,-24.168599096551084,-147.078116997524,102.94747917578634,13.68473739451218,12.847576475351495,-132.79641557565756,1.8860982974116547,27.1429981169738,5.157902013059672,-92.6084191604145,71.3230421502013,47.8679216790956,54.23228398138326,129.4458088465893,42.04992952987218,56.219463133367306,35.13054353387116,-43.80398048653765,1.995322656804564,-23.082101202665275,-68.79265216251946,65.45173847935665,-55.65121556268075,66.31663203773941,-50.15216840709069,20.33784411960476,117.8120950703883,-59.942744441061535,84.01445024244846,0.8589794622610386,-49.218442824810495,106.25148078477824,134.89849745645716,-115.875779070194,42.33389724045077,-70.4754911430795,-52.75181513404491,160.16900121190633,28.718375042976497,45.18520883792053,16.942337786719616,48.55083011712384,13.581619287641354,64.81342685110238,51.25694372869946,-92.85526496367903,-51.688566640204314,13.98689931493217,10.110839768323723,-112.6863029943036,-106.14505006269908,-9.678435441999309,-15.39672756986158,-77.41805720935075,15.978143008552935,-87.89705332470005,-22.137208364626545,-60.48862631037337],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e8c4aec3-9580-4812-97d8-ddaa5c37f50f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloader = load_csv(\"\")\n",
    "plot(plot_points= [(np.arange(0, len(dataloader[\"X_train\"])), dataloader[\"Y_train\"].to_numpy().reshape(100), \"traindata\")] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f8639a0-d7a9-446d-867c-3b9f2b7247f4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:00<00:00, 8237.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss for epoch 0: 0.44000239885519005\n",
      "eval Loss for epoch 0: 0.2960018844863038\n",
      "Training Loss for epoch 1: 0.31889073605096324\n",
      "Training Loss for epoch 2: 0.2927279152558354\n",
      "Training Loss for epoch 3: 0.2851446376504468\n",
      "Training Loss for epoch 4: 0.28244221405799014\n",
      "Training Loss for epoch 5: 0.28133086605419994\n",
      "Training Loss for epoch 6: 0.28082129013943524\n",
      "Training Loss for epoch 7: 0.2805669095790665\n",
      "Training Loss for epoch 8: 0.2804314371971184\n",
      "Training Loss for epoch 9: 0.2803558260638698\n",
      "Training Loss for epoch 10: 0.28031223608416533\n",
      "eval Loss for epoch 10: 0.2501590826230707\n",
      "Training Loss for epoch 11: 0.28028656027768356\n",
      "Training Loss for epoch 12: 0.28027122530452475\n",
      "Training Loss for epoch 13: 0.2802619857651783\n",
      "Training Loss for epoch 14: 0.2802563882421931\n",
      "Training Loss for epoch 15: 0.2802529856108106\n",
      "Training Loss for epoch 16: 0.28025091288143733\n",
      "Training Loss for epoch 17: 0.2802496486411926\n",
      "Training Loss for epoch 18: 0.2802488769184584\n",
      "Training Loss for epoch 19: 0.28024840560829617\n",
      "Training Loss for epoch 20: 0.280248117677933\n",
      "eval Loss for epoch 20: 0.2501871290777217\n",
      "Training Loss for epoch 21: 0.28024794174080253\n",
      "Training Loss for epoch 22: 0.28024783421996113\n",
      "Training Loss for epoch 23: 0.2802477685020272\n",
      "Training Loss for epoch 24: 0.28024772832897576\n",
      "Training Loss for epoch 25: 0.2802477037670871\n",
      "Training Loss for epoch 26: 0.2802476887461591\n",
      "Training Loss for epoch 27: 0.28024767955661883\n",
      "Training Loss for epoch 28: 0.2802476739314025\n",
      "Training Loss for epoch 29: 0.28024767048497745\n",
      "Training Loss for epoch 30: 0.2802476683705444\n",
      "eval Loss for epoch 30: 0.25018734079352556\n",
      "Training Loss for epoch 31: 0.28024766707055093\n",
      "Training Loss for epoch 32: 0.2802476662686671\n",
      "Training Loss for epoch 33: 0.2802476657715437\n",
      "Training Loss for epoch 34: 0.2802476654609938\n",
      "Training Loss for epoch 35: 0.28024766526476835\n",
      "Training Loss for epoch 36: 0.2802476651386954\n",
      "Training Loss for epoch 37: 0.28024766505576326\n",
      "Training Loss for epoch 38: 0.2802476649994493\n",
      "Training Loss for epoch 39: 0.2802476649596418\n",
      "Training Loss for epoch 40: 0.2802476649301488\n",
      "eval Loss for epoch 40: 0.25018734233647766\n",
      "Training Loss for epoch 41: 0.28024766490717357\n",
      "Training Loss for epoch 42: 0.28024766488838504\n",
      "Training Loss for epoch 43: 0.280247664872348\n",
      "Training Loss for epoch 44: 0.2802476648581751\n",
      "Training Loss for epoch 45: 0.28024766484531505\n",
      "Training Loss for epoch 46: 0.2802476648334219\n",
      "Training Loss for epoch 47: 0.2802476648222761\n",
      "Training Loss for epoch 48: 0.28024766481173535\n",
      "Training Loss for epoch 49: 0.2802476648017056\n",
      "Training Loss for epoch 50: 0.2802476647921222\n",
      "eval Loss for epoch 50: 0.25018734234965084\n",
      "Training Loss for epoch 51: 0.2802476647829392\n",
      "Training Loss for epoch 52: 0.28024766477412216\n",
      "Training Loss for epoch 53: 0.280247664765644\n",
      "Training Loss for epoch 54: 0.28024766475748303\n",
      "Training Loss for epoch 55: 0.28024766474962043\n",
      "Training Loss for epoch 56: 0.2802476647420397\n",
      "Training Loss for epoch 57: 0.2802476647347264\n",
      "Training Loss for epoch 58: 0.28024766472766677\n",
      "Training Loss for epoch 59: 0.2802476647208486\n",
      "Training Loss for epoch 60: 0.2802476647142604\n",
      "eval Loss for epoch 60: 0.2501873423510772\n",
      "Training Loss for epoch 61: 0.28024766470789114\n",
      "Training Loss for epoch 62: 0.2802476647017308\n",
      "Training Loss for epoch 63: 0.2802476646957697\n",
      "Training Loss for epoch 64: 0.28024766468999895\n",
      "Training Loss for epoch 65: 0.2802476646844099\n",
      "Training Loss for epoch 66: 0.2802476646789945\n",
      "Training Loss for epoch 67: 0.28024766467374496\n",
      "Training Loss for epoch 68: 0.28024766466865414\n",
      "Training Loss for epoch 69: 0.28024766466371537\n",
      "Training Loss for epoch 70: 0.28024766465892176\n",
      "eval Loss for epoch 70: 0.25018734235205736\n",
      "Training Loss for epoch 71: 0.2802476646542674\n",
      "Training Loss for epoch 72: 0.2802476646497464\n",
      "Training Loss for epoch 73: 0.2802476646453531\n",
      "Training Loss for epoch 74: 0.28024766464108253\n",
      "Training Loss for epoch 75: 0.2802476646369292\n",
      "Training Loss for epoch 76: 0.28024766463288886\n",
      "Training Loss for epoch 77: 0.2802476646289567\n",
      "Training Loss for epoch 78: 0.2802476646251285\n",
      "Training Loss for epoch 79: 0.28024766462140027\n",
      "Training Loss for epoch 80: 0.28024766461776807\n",
      "eval Loss for epoch 80: 0.2501873423528175\n",
      "Training Loss for epoch 81: 0.2802476646142283\n",
      "Training Loss for epoch 82: 0.2802476646107773\n",
      "Training Loss for epoch 83: 0.2802476646074121\n",
      "Training Loss for epoch 84: 0.2802476646041289\n",
      "Training Loss for epoch 85: 0.2802476646009254\n",
      "Training Loss for epoch 86: 0.2802476645977982\n",
      "Training Loss for epoch 87: 0.2802476645947447\n",
      "Training Loss for epoch 88: 0.2802476645917624\n",
      "Training Loss for epoch 89: 0.28024766458884887\n",
      "Training Loss for epoch 90: 0.28024766458600153\n",
      "eval Loss for epoch 90: 0.2501873423534384\n",
      "Training Loss for epoch 91: 0.28024766458321826\n",
      "Training Loss for epoch 92: 0.28024766458049677\n",
      "Training Loss for epoch 93: 0.2802476645778351\n",
      "Training Loss for epoch 94: 0.28024766457523137\n",
      "Training Loss for epoch 95: 0.28024766457268346\n",
      "Training Loss for epoch 96: 0.28024766457018974\n",
      "Training Loss for epoch 97: 0.2802476645677484\n",
      "Training Loss for epoch 98: 0.2802476645653579\n",
      "Training Loss for epoch 99: 0.28024766456301664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# activation function and its derivative\n",
    "tanh = lambda x: np.tanh(x)\n",
    "tanh_prime = lambda x: 1-np.tanh(x)**2 \n",
    "mse = lambda y, y_pred: np.mean((y-y_pred)**2)\n",
    "mse_prime = lambda y, y_pred : 2*(y_pred - y)/y.shape[0];\n",
    "\n",
    "# activation function and its derivative\n",
    "# def tanh(x):\n",
    "#     return np.tanh(x);\n",
    "\n",
    "# def tanh_prime(x):\n",
    "#     return 1-np.tanh(x)**2;\n",
    "\n",
    "# # loss function and its derivative\n",
    "# def mse(y_true, y_pred):\n",
    "#     return np.mean(np.power(y_true-y_pred, 2));\n",
    "\n",
    "# def mse_prime(y_true, y_pred):\n",
    "#     return 2*(y_pred-y_true)/y_true.size;\n",
    "\n",
    "\n",
    "# training data\n",
    "x_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
    "y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
    "\n",
    "# x_train = dataloader[\"X_train\"].to_numpy().reshape((dataloader[\"X_train\"].shape[0],1,dataloader[\"X_train\"].shape[1]))\n",
    "# y_train = dataloader[\"Y_train\"].to_numpy().reshape((dataloader[\"Y_train\"].shape[0],1,dataloader[\"Y_train\"].shape[1]))\n",
    "\n",
    "# network\n",
    "model = MLP(optimizer= None, hist= {}, learning_rate=0.1,\n",
    "            epochs = 100, eval_step=10, early_stop= False,\n",
    "            range_flag= False, loss= mse, loss_prime=mse_prime,\n",
    "            layers=[\n",
    "                FCLayer(input_size=x_train.shape[2], output_size=3, \n",
    "                            activation=tanh, activation_prime=tanh_prime,\n",
    "                        ),\n",
    "                FCLayer(input_size=3, output_size=1, \n",
    "                            activation=tanh, activation_prime=tanh_prime,\n",
    "                        ),\n",
    "                   ],\n",
    "            )\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0caeb1e6-d119-43bd-9f65-f8a88c1be4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[ 3.20803921e-05, -2.75320307e-05, -3.72440093e-06]]),\n",
       "  array([[0.2941115]])],\n",
       " [array([[ 4.95791742e-05, -3.58794677e-05, -4.82699482e-06]]),\n",
       "  array([[0.42262181]])],\n",
       " [array([[ 5.86614343e-05, -3.92743810e-05, -5.60868626e-06]]),\n",
       "  array([[0.48684457]])],\n",
       " [array([[ 6.32973868e-05, -4.09039607e-05, -6.32371782e-06]]),\n",
       "  array([[0.5223497]])],\n",
       " [array([[ 6.54730391e-05, -4.17524613e-05, -7.00855851e-06]]),\n",
       "  array([[0.54314309]])],\n",
       " [array([[ 6.62335198e-05, -4.22089311e-05, -7.66890261e-06]]),\n",
       "  array([[0.55573477]])],\n",
       " [array([[ 6.61612822e-05, -4.24532361e-05, -8.30639885e-06]]),\n",
       "  array([[0.56351392]])],\n",
       " [array([[ 6.55945066e-05, -4.25773011e-05, -8.92273398e-06]]),\n",
       "  array([[0.56837908]])],\n",
       " [array([[ 6.47349146e-05, -4.26312541e-05, -9.51990120e-06]]),\n",
       "  array([[0.57144505]])],\n",
       " [array([[ 6.37049117e-05, -4.26436030e-05, -1.00999332e-05]]),\n",
       "  array([[0.57338643]])],\n",
       " [array([[ 6.25795535e-05, -4.26310047e-05, -1.06646896e-05]]),\n",
       "  array([[0.57461943]])],\n",
       " [array([[ 6.14051264e-05, -4.26033597e-05, -1.12157595e-05]]),\n",
       "  array([[0.57540403]])],\n",
       " [array([[ 6.02102364e-05, -4.25666141e-05, -1.17544443e-05]]),\n",
       "  array([[0.5759039]])],\n",
       " [array([[ 5.90125427e-05, -4.25243600e-05, -1.22817839e-05]]),\n",
       "  array([[0.57622261]])],\n",
       " [array([[ 5.78228957e-05, -4.24787718e-05, -1.27985991e-05]]),\n",
       "  array([[0.57642593]])],\n",
       " [array([[ 5.66478988e-05, -4.24311647e-05, -1.33055371e-05]]),\n",
       "  array([[0.57655566]])],\n",
       " [array([[ 5.54915019e-05, -4.23823306e-05, -1.38031113e-05]]),\n",
       "  array([[0.57663847]])],\n",
       " [array([[ 5.43559965e-05, -4.23327425e-05, -1.42917356e-05]]),\n",
       "  array([[0.57669132]])],\n",
       " [array([[ 5.32426377e-05, -4.22826783e-05, -1.47717506e-05]]),\n",
       "  array([[0.57672506]])],\n",
       " [array([[ 5.21520340e-05, -4.22322971e-05, -1.52434431e-05]]),\n",
       "  array([[0.5767466]])],\n",
       " [array([[ 5.10843919e-05, -4.21816859e-05, -1.57070612e-05]]),\n",
       "  array([[0.57676036]])],\n",
       " [array([[ 5.00396685e-05, -4.21308876e-05, -1.61628250e-05]]),\n",
       "  array([[0.57676914]])],\n",
       " [array([[ 4.90176684e-05, -4.20799190e-05, -1.66109339e-05]]),\n",
       "  array([[0.57677474]])],\n",
       " [array([[ 4.80181034e-05, -4.20287811e-05, -1.70515721e-05]]),\n",
       "  array([[0.57677832]])],\n",
       " [array([[ 4.70406307e-05, -4.19774660e-05, -1.74849126e-05]]),\n",
       "  array([[0.57678061]])],\n",
       " [array([[ 4.60848762e-05, -4.19259606e-05, -1.79111192e-05]]),\n",
       "  array([[0.57678207]])],\n",
       " [array([[ 4.51504497e-05, -4.18742493e-05, -1.83303491e-05]]),\n",
       "  array([[0.576783]])],\n",
       " [array([[ 4.42369538e-05, -4.18223152e-05, -1.87427535e-05]]),\n",
       "  array([[0.57678359]])],\n",
       " [array([[ 4.33439899e-05, -4.17701413e-05, -1.91484788e-05]]),\n",
       "  array([[0.57678397]])],\n",
       " [array([[ 4.24711618e-05, -4.17177107e-05, -1.95476672e-05]]),\n",
       "  array([[0.57678422]])],\n",
       " [array([[ 4.16180773e-05, -4.16650070e-05, -1.99404570e-05]]),\n",
       "  array([[0.57678437]])],\n",
       " [array([[ 4.07843503e-05, -4.16120149e-05, -2.03269830e-05]]),\n",
       "  array([[0.57678447]])],\n",
       " [array([[ 3.99696010e-05, -4.15587196e-05, -2.07073768e-05]]),\n",
       "  array([[0.57678454]])],\n",
       " [array([[ 3.91734564e-05, -4.15051073e-05, -2.10817669e-05]]),\n",
       "  array([[0.57678458]])],\n",
       " [array([[ 3.83955507e-05, -4.14511650e-05, -2.14502787e-05]]),\n",
       "  array([[0.5767846]])],\n",
       " [array([[ 3.76355251e-05, -4.13968807e-05, -2.18130348e-05]]),\n",
       "  array([[0.57678462]])],\n",
       " [array([[ 3.68930279e-05, -4.13422433e-05, -2.21701553e-05]]),\n",
       "  array([[0.57678463]])],\n",
       " [array([[ 3.61677146e-05, -4.12872422e-05, -2.25217573e-05]]),\n",
       "  array([[0.57678464]])],\n",
       " [array([[ 3.54592476e-05, -4.12318680e-05, -2.28679555e-05]]),\n",
       "  array([[0.57678464]])],\n",
       " [array([[ 3.47672959e-05, -4.11761119e-05, -2.32088620e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 3.40915355e-05, -4.11199659e-05, -2.35445865e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 3.34316487e-05, -4.10634226e-05, -2.38752363e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 3.27873246e-05, -4.10064755e-05, -2.42009163e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 3.21582582e-05, -4.09491186e-05, -2.45217291e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 3.15441510e-05, -4.08913467e-05, -2.48377751e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 3.09447102e-05, -4.08331550e-05, -2.51491527e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 3.03596494e-05, -4.07745394e-05, -2.54559579e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 2.97886874e-05, -4.07154964e-05, -2.57582848e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 2.92315491e-05, -4.06560230e-05, -2.60562253e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 2.86879649e-05, -4.05961167e-05, -2.63498695e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 2.81576704e-05, -4.05357755e-05, -2.66393056e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 2.76404067e-05, -4.04749980e-05, -2.69246197e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 2.71359200e-05, -4.04137830e-05, -2.72058961e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 2.66439617e-05, -4.03521298e-05, -2.74832174e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 2.61642881e-05, -4.02900384e-05, -2.77566644e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 2.56966604e-05, -4.02275088e-05, -2.80263162e-05]]),\n",
       "  array([[0.57678465]])],\n",
       " [array([[ 2.52408445e-05, -4.01645416e-05, -2.82922501e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 2.47966110e-05, -4.01011377e-05, -2.85545419e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 2.43637352e-05, -4.00372983e-05, -2.88132657e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 2.39419967e-05, -3.99730250e-05, -2.90684940e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 2.35311797e-05, -3.99083196e-05, -2.93202978e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 2.31310723e-05, -3.98431844e-05, -2.95687467e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 2.27414673e-05, -3.97776217e-05, -2.98139086e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 2.23621613e-05, -3.97116343e-05, -3.00558503e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 2.19929549e-05, -3.96452252e-05, -3.02946369e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 2.16336529e-05, -3.95783974e-05, -3.05303322e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 2.12840636e-05, -3.95111545e-05, -3.07629988e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 2.09439994e-05, -3.94435000e-05, -3.09926977e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 2.06132762e-05, -3.93754379e-05, -3.12194890e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 2.02917137e-05, -3.93069721e-05, -3.14434313e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.99791350e-05, -3.92381068e-05, -3.16645819e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.96753667e-05, -3.91688464e-05, -3.18829972e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.93802389e-05, -3.90991954e-05, -3.20987322e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.90935849e-05, -3.90291585e-05, -3.23118409e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.88152413e-05, -3.89587405e-05, -3.25223759e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.85450481e-05, -3.88879464e-05, -3.27303891e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.82828481e-05, -3.88167811e-05, -3.29359310e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.80284873e-05, -3.87452500e-05, -3.31390513e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.77818149e-05, -3.86733583e-05, -3.33397985e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.75426828e-05, -3.86011113e-05, -3.35382202e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.73109459e-05, -3.85285145e-05, -3.37343630e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.70864618e-05, -3.84555735e-05, -3.39282725e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.68690910e-05, -3.83822939e-05, -3.41199935e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.66586967e-05, -3.83086815e-05, -3.43095696e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.64551446e-05, -3.82347418e-05, -3.44970439e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.62583033e-05, -3.81604809e-05, -3.46824583e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.60680437e-05, -3.80859046e-05, -3.48658540e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.58842393e-05, -3.80110187e-05, -3.50472713e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.57067659e-05, -3.79358292e-05, -3.52267497e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.55355020e-05, -3.78603421e-05, -3.54043279e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.53703281e-05, -3.77845635e-05, -3.55800439e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.52111272e-05, -3.77084993e-05, -3.57539348e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.50577846e-05, -3.76321557e-05, -3.59260370e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.49101876e-05, -3.75555387e-05, -3.60963861e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.47682259e-05, -3.74786544e-05, -3.62650171e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.46317912e-05, -3.74015090e-05, -3.64319644e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.45007773e-05, -3.73241085e-05, -3.65972613e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.43750800e-05, -3.72464590e-05, -3.67609409e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.42545972e-05, -3.71685666e-05, -3.69230353e-05]]),\n",
       "  array([[0.57678466]])],\n",
       " [array([[ 1.41392287e-05, -3.70904375e-05, -3.70835762e-05]]),\n",
       "  array([[0.57678466]])]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hist[\"bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "05959881-99f8-442d-8569-2b85e738631c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader[\"X_train\"].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c438a2a-70ec-4e9e-89a3-f4b19ee7a22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader[\"Y_train\"].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eb06d80-485e-4b94-99f3-23e88211f765",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/1000   error=0.697134\n",
      "epoch 2/1000   error=0.371360\n",
      "epoch 3/1000   error=0.357053\n",
      "epoch 4/1000   error=0.354102\n",
      "epoch 5/1000   error=0.352231\n",
      "epoch 6/1000   error=0.350506\n",
      "epoch 7/1000   error=0.348794\n",
      "epoch 8/1000   error=0.347083\n",
      "epoch 9/1000   error=0.345382\n",
      "epoch 10/1000   error=0.343700\n",
      "epoch 11/1000   error=0.342047\n",
      "epoch 12/1000   error=0.340427\n",
      "epoch 13/1000   error=0.338844\n",
      "epoch 14/1000   error=0.337302\n",
      "epoch 15/1000   error=0.335802\n",
      "epoch 16/1000   error=0.334345\n",
      "epoch 17/1000   error=0.332931\n",
      "epoch 18/1000   error=0.331561\n",
      "epoch 19/1000   error=0.330234\n",
      "epoch 20/1000   error=0.328950\n",
      "epoch 21/1000   error=0.327708\n",
      "epoch 22/1000   error=0.326507\n",
      "epoch 23/1000   error=0.325346\n",
      "epoch 24/1000   error=0.324224\n",
      "epoch 25/1000   error=0.323140\n",
      "epoch 26/1000   error=0.322092\n",
      "epoch 27/1000   error=0.321079\n",
      "epoch 28/1000   error=0.320099\n",
      "epoch 29/1000   error=0.319151\n",
      "epoch 30/1000   error=0.318234\n",
      "epoch 31/1000   error=0.317345\n",
      "epoch 32/1000   error=0.316485\n",
      "epoch 33/1000   error=0.315650\n",
      "epoch 34/1000   error=0.314839\n",
      "epoch 35/1000   error=0.314051\n",
      "epoch 36/1000   error=0.313285\n",
      "epoch 37/1000   error=0.312538\n",
      "epoch 38/1000   error=0.311810\n",
      "epoch 39/1000   error=0.311098\n",
      "epoch 40/1000   error=0.310402\n",
      "epoch 41/1000   error=0.309719\n",
      "epoch 42/1000   error=0.309048\n",
      "epoch 43/1000   error=0.308387\n",
      "epoch 44/1000   error=0.307736\n",
      "epoch 45/1000   error=0.307092\n",
      "epoch 46/1000   error=0.306453\n",
      "epoch 47/1000   error=0.305819\n",
      "epoch 48/1000   error=0.305188\n",
      "epoch 49/1000   error=0.304558\n",
      "epoch 50/1000   error=0.303927\n",
      "epoch 51/1000   error=0.303294\n",
      "epoch 52/1000   error=0.302657\n",
      "epoch 53/1000   error=0.302015\n",
      "epoch 54/1000   error=0.301366\n",
      "epoch 55/1000   error=0.300708\n",
      "epoch 56/1000   error=0.300040\n",
      "epoch 57/1000   error=0.299360\n",
      "epoch 58/1000   error=0.298665\n",
      "epoch 59/1000   error=0.297955\n",
      "epoch 60/1000   error=0.297228\n",
      "epoch 61/1000   error=0.296481\n",
      "epoch 62/1000   error=0.295714\n",
      "epoch 63/1000   error=0.294924\n",
      "epoch 64/1000   error=0.294109\n",
      "epoch 65/1000   error=0.293268\n",
      "epoch 66/1000   error=0.292400\n",
      "epoch 67/1000   error=0.291501\n",
      "epoch 68/1000   error=0.290571\n",
      "epoch 69/1000   error=0.289609\n",
      "epoch 70/1000   error=0.288612\n",
      "epoch 71/1000   error=0.287579\n",
      "epoch 72/1000   error=0.286508\n",
      "epoch 73/1000   error=0.285399\n",
      "epoch 74/1000   error=0.284250\n",
      "epoch 75/1000   error=0.283059\n",
      "epoch 76/1000   error=0.281827\n",
      "epoch 77/1000   error=0.280552\n",
      "epoch 78/1000   error=0.279233\n",
      "epoch 79/1000   error=0.277871\n",
      "epoch 80/1000   error=0.276464\n",
      "epoch 81/1000   error=0.275014\n",
      "epoch 82/1000   error=0.273519\n",
      "epoch 83/1000   error=0.271982\n",
      "epoch 84/1000   error=0.270402\n",
      "epoch 85/1000   error=0.268781\n",
      "epoch 86/1000   error=0.267120\n",
      "epoch 87/1000   error=0.265420\n",
      "epoch 88/1000   error=0.263684\n",
      "epoch 89/1000   error=0.261913\n",
      "epoch 90/1000   error=0.260111\n",
      "epoch 91/1000   error=0.258280\n",
      "epoch 92/1000   error=0.256422\n",
      "epoch 93/1000   error=0.254541\n",
      "epoch 94/1000   error=0.252639\n",
      "epoch 95/1000   error=0.250719\n",
      "epoch 96/1000   error=0.248785\n",
      "epoch 97/1000   error=0.246840\n",
      "epoch 98/1000   error=0.244885\n",
      "epoch 99/1000   error=0.242924\n",
      "epoch 100/1000   error=0.240959\n",
      "epoch 101/1000   error=0.238991\n",
      "epoch 102/1000   error=0.237023\n",
      "epoch 103/1000   error=0.235055\n",
      "epoch 104/1000   error=0.233088\n",
      "epoch 105/1000   error=0.231123\n",
      "epoch 106/1000   error=0.229160\n",
      "epoch 107/1000   error=0.227197\n",
      "epoch 108/1000   error=0.225235\n",
      "epoch 109/1000   error=0.223271\n",
      "epoch 110/1000   error=0.221305\n",
      "epoch 111/1000   error=0.219335\n",
      "epoch 112/1000   error=0.217358\n",
      "epoch 113/1000   error=0.215372\n",
      "epoch 114/1000   error=0.213375\n",
      "epoch 115/1000   error=0.211362\n",
      "epoch 116/1000   error=0.209332\n",
      "epoch 117/1000   error=0.207280\n",
      "epoch 118/1000   error=0.205204\n",
      "epoch 119/1000   error=0.203099\n",
      "epoch 120/1000   error=0.200961\n",
      "epoch 121/1000   error=0.198786\n",
      "epoch 122/1000   error=0.196570\n",
      "epoch 123/1000   error=0.194307\n",
      "epoch 124/1000   error=0.191993\n",
      "epoch 125/1000   error=0.189622\n",
      "epoch 126/1000   error=0.187189\n",
      "epoch 127/1000   error=0.184690\n",
      "epoch 128/1000   error=0.182117\n",
      "epoch 129/1000   error=0.179467\n",
      "epoch 130/1000   error=0.176733\n",
      "epoch 131/1000   error=0.173910\n",
      "epoch 132/1000   error=0.170993\n",
      "epoch 133/1000   error=0.167979\n",
      "epoch 134/1000   error=0.164862\n",
      "epoch 135/1000   error=0.161639\n",
      "epoch 136/1000   error=0.158307\n",
      "epoch 137/1000   error=0.154865\n",
      "epoch 138/1000   error=0.151311\n",
      "epoch 139/1000   error=0.147646\n",
      "epoch 140/1000   error=0.143870\n",
      "epoch 141/1000   error=0.139986\n",
      "epoch 142/1000   error=0.135998\n",
      "epoch 143/1000   error=0.131911\n",
      "epoch 144/1000   error=0.127732\n",
      "epoch 145/1000   error=0.123472\n",
      "epoch 146/1000   error=0.119139\n",
      "epoch 147/1000   error=0.114747\n",
      "epoch 148/1000   error=0.110311\n",
      "epoch 149/1000   error=0.105846\n",
      "epoch 150/1000   error=0.101371\n",
      "epoch 151/1000   error=0.096906\n",
      "epoch 152/1000   error=0.092470\n",
      "epoch 153/1000   error=0.088084\n",
      "epoch 154/1000   error=0.083769\n",
      "epoch 155/1000   error=0.079545\n",
      "epoch 156/1000   error=0.075432\n",
      "epoch 157/1000   error=0.071447\n",
      "epoch 158/1000   error=0.067604\n",
      "epoch 159/1000   error=0.063917\n",
      "epoch 160/1000   error=0.060394\n",
      "epoch 161/1000   error=0.057045\n",
      "epoch 162/1000   error=0.053871\n",
      "epoch 163/1000   error=0.050874\n",
      "epoch 164/1000   error=0.048054\n",
      "epoch 165/1000   error=0.045407\n",
      "epoch 166/1000   error=0.042928\n",
      "epoch 167/1000   error=0.040610\n",
      "epoch 168/1000   error=0.038446\n",
      "epoch 169/1000   error=0.036429\n",
      "epoch 170/1000   error=0.034549\n",
      "epoch 171/1000   error=0.032798\n",
      "epoch 172/1000   error=0.031167\n",
      "epoch 173/1000   error=0.029649\n",
      "epoch 174/1000   error=0.028234\n",
      "epoch 175/1000   error=0.026916\n",
      "epoch 176/1000   error=0.025687\n",
      "epoch 177/1000   error=0.024541\n",
      "epoch 178/1000   error=0.023470\n",
      "epoch 179/1000   error=0.022469\n",
      "epoch 180/1000   error=0.021533\n",
      "epoch 181/1000   error=0.020657\n",
      "epoch 182/1000   error=0.019835\n",
      "epoch 183/1000   error=0.019065\n",
      "epoch 184/1000   error=0.018341\n",
      "epoch 185/1000   error=0.017660\n",
      "epoch 186/1000   error=0.017020\n",
      "epoch 187/1000   error=0.016416\n",
      "epoch 188/1000   error=0.015847\n",
      "epoch 189/1000   error=0.015310\n",
      "epoch 190/1000   error=0.014802\n",
      "epoch 191/1000   error=0.014321\n",
      "epoch 192/1000   error=0.013866\n",
      "epoch 193/1000   error=0.013435\n",
      "epoch 194/1000   error=0.013026\n",
      "epoch 195/1000   error=0.012637\n",
      "epoch 196/1000   error=0.012268\n",
      "epoch 197/1000   error=0.011917\n",
      "epoch 198/1000   error=0.011582\n",
      "epoch 199/1000   error=0.011263\n",
      "epoch 200/1000   error=0.010959\n",
      "epoch 201/1000   error=0.010669\n",
      "epoch 202/1000   error=0.010392\n",
      "epoch 203/1000   error=0.010127\n",
      "epoch 204/1000   error=0.009873\n",
      "epoch 205/1000   error=0.009630\n",
      "epoch 206/1000   error=0.009397\n",
      "epoch 207/1000   error=0.009174\n",
      "epoch 208/1000   error=0.008960\n",
      "epoch 209/1000   error=0.008755\n",
      "epoch 210/1000   error=0.008558\n",
      "epoch 211/1000   error=0.008368\n",
      "epoch 212/1000   error=0.008185\n",
      "epoch 213/1000   error=0.008010\n",
      "epoch 214/1000   error=0.007841\n",
      "epoch 215/1000   error=0.007678\n",
      "epoch 216/1000   error=0.007521\n",
      "epoch 217/1000   error=0.007369\n",
      "epoch 218/1000   error=0.007223\n",
      "epoch 219/1000   error=0.007082\n",
      "epoch 220/1000   error=0.006946\n",
      "epoch 221/1000   error=0.006814\n",
      "epoch 222/1000   error=0.006687\n",
      "epoch 223/1000   error=0.006564\n",
      "epoch 224/1000   error=0.006444\n",
      "epoch 225/1000   error=0.006329\n",
      "epoch 226/1000   error=0.006217\n",
      "epoch 227/1000   error=0.006109\n",
      "epoch 228/1000   error=0.006004\n",
      "epoch 229/1000   error=0.005902\n",
      "epoch 230/1000   error=0.005803\n",
      "epoch 231/1000   error=0.005707\n",
      "epoch 232/1000   error=0.005614\n",
      "epoch 233/1000   error=0.005524\n",
      "epoch 234/1000   error=0.005436\n",
      "epoch 235/1000   error=0.005351\n",
      "epoch 236/1000   error=0.005268\n",
      "epoch 237/1000   error=0.005187\n",
      "epoch 238/1000   error=0.005109\n",
      "epoch 239/1000   error=0.005032\n",
      "epoch 240/1000   error=0.004958\n",
      "epoch 241/1000   error=0.004885\n",
      "epoch 242/1000   error=0.004815\n",
      "epoch 243/1000   error=0.004746\n",
      "epoch 244/1000   error=0.004679\n",
      "epoch 245/1000   error=0.004614\n",
      "epoch 246/1000   error=0.004550\n",
      "epoch 247/1000   error=0.004488\n",
      "epoch 248/1000   error=0.004428\n",
      "epoch 249/1000   error=0.004369\n",
      "epoch 250/1000   error=0.004311\n",
      "epoch 251/1000   error=0.004254\n",
      "epoch 252/1000   error=0.004199\n",
      "epoch 253/1000   error=0.004146\n",
      "epoch 254/1000   error=0.004093\n",
      "epoch 255/1000   error=0.004042\n",
      "epoch 256/1000   error=0.003992\n",
      "epoch 257/1000   error=0.003943\n",
      "epoch 258/1000   error=0.003895\n",
      "epoch 259/1000   error=0.003848\n",
      "epoch 260/1000   error=0.003802\n",
      "epoch 261/1000   error=0.003757\n",
      "epoch 262/1000   error=0.003713\n",
      "epoch 263/1000   error=0.003670\n",
      "epoch 264/1000   error=0.003628\n",
      "epoch 265/1000   error=0.003587\n",
      "epoch 266/1000   error=0.003546\n",
      "epoch 267/1000   error=0.003506\n",
      "epoch 268/1000   error=0.003468\n",
      "epoch 269/1000   error=0.003430\n",
      "epoch 270/1000   error=0.003392\n",
      "epoch 271/1000   error=0.003356\n",
      "epoch 272/1000   error=0.003320\n",
      "epoch 273/1000   error=0.003285\n",
      "epoch 274/1000   error=0.003250\n",
      "epoch 275/1000   error=0.003217\n",
      "epoch 276/1000   error=0.003183\n",
      "epoch 277/1000   error=0.003151\n",
      "epoch 278/1000   error=0.003119\n",
      "epoch 279/1000   error=0.003087\n",
      "epoch 280/1000   error=0.003057\n",
      "epoch 281/1000   error=0.003026\n",
      "epoch 282/1000   error=0.002997\n",
      "epoch 283/1000   error=0.002968\n",
      "epoch 284/1000   error=0.002939\n",
      "epoch 285/1000   error=0.002911\n",
      "epoch 286/1000   error=0.002883\n",
      "epoch 287/1000   error=0.002856\n",
      "epoch 288/1000   error=0.002829\n",
      "epoch 289/1000   error=0.002803\n",
      "epoch 290/1000   error=0.002777\n",
      "epoch 291/1000   error=0.002752\n",
      "epoch 292/1000   error=0.002727\n",
      "epoch 293/1000   error=0.002702\n",
      "epoch 294/1000   error=0.002678\n",
      "epoch 295/1000   error=0.002654\n",
      "epoch 296/1000   error=0.002631\n",
      "epoch 297/1000   error=0.002608\n",
      "epoch 298/1000   error=0.002585\n",
      "epoch 299/1000   error=0.002563\n",
      "epoch 300/1000   error=0.002541\n",
      "epoch 301/1000   error=0.002519\n",
      "epoch 302/1000   error=0.002498\n",
      "epoch 303/1000   error=0.002477\n",
      "epoch 304/1000   error=0.002457\n",
      "epoch 305/1000   error=0.002436\n",
      "epoch 306/1000   error=0.002416\n",
      "epoch 307/1000   error=0.002397\n",
      "epoch 308/1000   error=0.002377\n",
      "epoch 309/1000   error=0.002358\n",
      "epoch 310/1000   error=0.002339\n",
      "epoch 311/1000   error=0.002321\n",
      "epoch 312/1000   error=0.002302\n",
      "epoch 313/1000   error=0.002284\n",
      "epoch 314/1000   error=0.002267\n",
      "epoch 315/1000   error=0.002249\n",
      "epoch 316/1000   error=0.002232\n",
      "epoch 317/1000   error=0.002215\n",
      "epoch 318/1000   error=0.002198\n",
      "epoch 319/1000   error=0.002182\n",
      "epoch 320/1000   error=0.002165\n",
      "epoch 321/1000   error=0.002149\n",
      "epoch 322/1000   error=0.002133\n",
      "epoch 323/1000   error=0.002118\n",
      "epoch 324/1000   error=0.002102\n",
      "epoch 325/1000   error=0.002087\n",
      "epoch 326/1000   error=0.002072\n",
      "epoch 327/1000   error=0.002057\n",
      "epoch 328/1000   error=0.002042\n",
      "epoch 329/1000   error=0.002028\n",
      "epoch 330/1000   error=0.002014\n",
      "epoch 331/1000   error=0.001999\n",
      "epoch 332/1000   error=0.001986\n",
      "epoch 333/1000   error=0.001972\n",
      "epoch 334/1000   error=0.001958\n",
      "epoch 335/1000   error=0.001945\n",
      "epoch 336/1000   error=0.001932\n",
      "epoch 337/1000   error=0.001919\n",
      "epoch 338/1000   error=0.001906\n",
      "epoch 339/1000   error=0.001893\n",
      "epoch 340/1000   error=0.001880\n",
      "epoch 341/1000   error=0.001868\n",
      "epoch 342/1000   error=0.001856\n",
      "epoch 343/1000   error=0.001844\n",
      "epoch 344/1000   error=0.001832\n",
      "epoch 345/1000   error=0.001820\n",
      "epoch 346/1000   error=0.001808\n",
      "epoch 347/1000   error=0.001796\n",
      "epoch 348/1000   error=0.001785\n",
      "epoch 349/1000   error=0.001774\n",
      "epoch 350/1000   error=0.001763\n",
      "epoch 351/1000   error=0.001752\n",
      "epoch 352/1000   error=0.001741\n",
      "epoch 353/1000   error=0.001730\n",
      "epoch 354/1000   error=0.001719\n",
      "epoch 355/1000   error=0.001709\n",
      "epoch 356/1000   error=0.001698\n",
      "epoch 357/1000   error=0.001688\n",
      "epoch 358/1000   error=0.001678\n",
      "epoch 359/1000   error=0.001668\n",
      "epoch 360/1000   error=0.001658\n",
      "epoch 361/1000   error=0.001648\n",
      "epoch 362/1000   error=0.001638\n",
      "epoch 363/1000   error=0.001629\n",
      "epoch 364/1000   error=0.001619\n",
      "epoch 365/1000   error=0.001610\n",
      "epoch 366/1000   error=0.001600\n",
      "epoch 367/1000   error=0.001591\n",
      "epoch 368/1000   error=0.001582\n",
      "epoch 369/1000   error=0.001573\n",
      "epoch 370/1000   error=0.001564\n",
      "epoch 371/1000   error=0.001555\n",
      "epoch 372/1000   error=0.001546\n",
      "epoch 373/1000   error=0.001538\n",
      "epoch 374/1000   error=0.001529\n",
      "epoch 375/1000   error=0.001521\n",
      "epoch 376/1000   error=0.001512\n",
      "epoch 377/1000   error=0.001504\n",
      "epoch 378/1000   error=0.001496\n",
      "epoch 379/1000   error=0.001488\n",
      "epoch 380/1000   error=0.001480\n",
      "epoch 381/1000   error=0.001472\n",
      "epoch 382/1000   error=0.001464\n",
      "epoch 383/1000   error=0.001456\n",
      "epoch 384/1000   error=0.001448\n",
      "epoch 385/1000   error=0.001440\n",
      "epoch 386/1000   error=0.001433\n",
      "epoch 387/1000   error=0.001425\n",
      "epoch 388/1000   error=0.001418\n",
      "epoch 389/1000   error=0.001410\n",
      "epoch 390/1000   error=0.001403\n",
      "epoch 391/1000   error=0.001396\n",
      "epoch 392/1000   error=0.001389\n",
      "epoch 393/1000   error=0.001382\n",
      "epoch 394/1000   error=0.001375\n",
      "epoch 395/1000   error=0.001368\n",
      "epoch 396/1000   error=0.001361\n",
      "epoch 397/1000   error=0.001354\n",
      "epoch 398/1000   error=0.001347\n",
      "epoch 399/1000   error=0.001340\n",
      "epoch 400/1000   error=0.001334\n",
      "epoch 401/1000   error=0.001327\n",
      "epoch 402/1000   error=0.001321\n",
      "epoch 403/1000   error=0.001314\n",
      "epoch 404/1000   error=0.001308\n",
      "epoch 405/1000   error=0.001301\n",
      "epoch 406/1000   error=0.001295\n",
      "epoch 407/1000   error=0.001289\n",
      "epoch 408/1000   error=0.001283\n",
      "epoch 409/1000   error=0.001277\n",
      "epoch 410/1000   error=0.001271\n",
      "epoch 411/1000   error=0.001265\n",
      "epoch 412/1000   error=0.001259\n",
      "epoch 413/1000   error=0.001253\n",
      "epoch 414/1000   error=0.001247\n",
      "epoch 415/1000   error=0.001241\n",
      "epoch 416/1000   error=0.001235\n",
      "epoch 417/1000   error=0.001229\n",
      "epoch 418/1000   error=0.001224\n",
      "epoch 419/1000   error=0.001218\n",
      "epoch 420/1000   error=0.001213\n",
      "epoch 421/1000   error=0.001207\n",
      "epoch 422/1000   error=0.001202\n",
      "epoch 423/1000   error=0.001196\n",
      "epoch 424/1000   error=0.001191\n",
      "epoch 425/1000   error=0.001185\n",
      "epoch 426/1000   error=0.001180\n",
      "epoch 427/1000   error=0.001175\n",
      "epoch 428/1000   error=0.001170\n",
      "epoch 429/1000   error=0.001165\n",
      "epoch 430/1000   error=0.001159\n",
      "epoch 431/1000   error=0.001154\n",
      "epoch 432/1000   error=0.001149\n",
      "epoch 433/1000   error=0.001144\n",
      "epoch 434/1000   error=0.001139\n",
      "epoch 435/1000   error=0.001134\n",
      "epoch 436/1000   error=0.001130\n",
      "epoch 437/1000   error=0.001125\n",
      "epoch 438/1000   error=0.001120\n",
      "epoch 439/1000   error=0.001115\n",
      "epoch 440/1000   error=0.001110\n",
      "epoch 441/1000   error=0.001106\n",
      "epoch 442/1000   error=0.001101\n",
      "epoch 443/1000   error=0.001097\n",
      "epoch 444/1000   error=0.001092\n",
      "epoch 445/1000   error=0.001087\n",
      "epoch 446/1000   error=0.001083\n",
      "epoch 447/1000   error=0.001078\n",
      "epoch 448/1000   error=0.001074\n",
      "epoch 449/1000   error=0.001070\n",
      "epoch 450/1000   error=0.001065\n",
      "epoch 451/1000   error=0.001061\n",
      "epoch 452/1000   error=0.001057\n",
      "epoch 453/1000   error=0.001052\n",
      "epoch 454/1000   error=0.001048\n",
      "epoch 455/1000   error=0.001044\n",
      "epoch 456/1000   error=0.001040\n",
      "epoch 457/1000   error=0.001035\n",
      "epoch 458/1000   error=0.001031\n",
      "epoch 459/1000   error=0.001027\n",
      "epoch 460/1000   error=0.001023\n",
      "epoch 461/1000   error=0.001019\n",
      "epoch 462/1000   error=0.001015\n",
      "epoch 463/1000   error=0.001011\n",
      "epoch 464/1000   error=0.001007\n",
      "epoch 465/1000   error=0.001003\n",
      "epoch 466/1000   error=0.001000\n",
      "epoch 467/1000   error=0.000996\n",
      "epoch 468/1000   error=0.000992\n",
      "epoch 469/1000   error=0.000988\n",
      "epoch 470/1000   error=0.000984\n",
      "epoch 471/1000   error=0.000981\n",
      "epoch 472/1000   error=0.000977\n",
      "epoch 473/1000   error=0.000973\n",
      "epoch 474/1000   error=0.000969\n",
      "epoch 475/1000   error=0.000966\n",
      "epoch 476/1000   error=0.000962\n",
      "epoch 477/1000   error=0.000959\n",
      "epoch 478/1000   error=0.000955\n",
      "epoch 479/1000   error=0.000951\n",
      "epoch 480/1000   error=0.000948\n",
      "epoch 481/1000   error=0.000944\n",
      "epoch 482/1000   error=0.000941\n",
      "epoch 483/1000   error=0.000938\n",
      "epoch 484/1000   error=0.000934\n",
      "epoch 485/1000   error=0.000931\n",
      "epoch 486/1000   error=0.000927\n",
      "epoch 487/1000   error=0.000924\n",
      "epoch 488/1000   error=0.000921\n",
      "epoch 489/1000   error=0.000917\n",
      "epoch 490/1000   error=0.000914\n",
      "epoch 491/1000   error=0.000911\n",
      "epoch 492/1000   error=0.000908\n",
      "epoch 493/1000   error=0.000904\n",
      "epoch 494/1000   error=0.000901\n",
      "epoch 495/1000   error=0.000898\n",
      "epoch 496/1000   error=0.000895\n",
      "epoch 497/1000   error=0.000892\n",
      "epoch 498/1000   error=0.000889\n",
      "epoch 499/1000   error=0.000885\n",
      "epoch 500/1000   error=0.000882\n",
      "epoch 501/1000   error=0.000879\n",
      "epoch 502/1000   error=0.000876\n",
      "epoch 503/1000   error=0.000873\n",
      "epoch 504/1000   error=0.000870\n",
      "epoch 505/1000   error=0.000867\n",
      "epoch 506/1000   error=0.000864\n",
      "epoch 507/1000   error=0.000861\n",
      "epoch 508/1000   error=0.000859\n",
      "epoch 509/1000   error=0.000856\n",
      "epoch 510/1000   error=0.000853\n",
      "epoch 511/1000   error=0.000850\n",
      "epoch 512/1000   error=0.000847\n",
      "epoch 513/1000   error=0.000844\n",
      "epoch 514/1000   error=0.000841\n",
      "epoch 515/1000   error=0.000839\n",
      "epoch 516/1000   error=0.000836\n",
      "epoch 517/1000   error=0.000833\n",
      "epoch 518/1000   error=0.000830\n",
      "epoch 519/1000   error=0.000828\n",
      "epoch 520/1000   error=0.000825\n",
      "epoch 521/1000   error=0.000822\n",
      "epoch 522/1000   error=0.000819\n",
      "epoch 523/1000   error=0.000817\n",
      "epoch 524/1000   error=0.000814\n",
      "epoch 525/1000   error=0.000812\n",
      "epoch 526/1000   error=0.000809\n",
      "epoch 527/1000   error=0.000806\n",
      "epoch 528/1000   error=0.000804\n",
      "epoch 529/1000   error=0.000801\n",
      "epoch 530/1000   error=0.000799\n",
      "epoch 531/1000   error=0.000796\n",
      "epoch 532/1000   error=0.000794\n",
      "epoch 533/1000   error=0.000791\n",
      "epoch 534/1000   error=0.000789\n",
      "epoch 535/1000   error=0.000786\n",
      "epoch 536/1000   error=0.000784\n",
      "epoch 537/1000   error=0.000781\n",
      "epoch 538/1000   error=0.000779\n",
      "epoch 539/1000   error=0.000776\n",
      "epoch 540/1000   error=0.000774\n",
      "epoch 541/1000   error=0.000772\n",
      "epoch 542/1000   error=0.000769\n",
      "epoch 543/1000   error=0.000767\n",
      "epoch 544/1000   error=0.000764\n",
      "epoch 545/1000   error=0.000762\n",
      "epoch 546/1000   error=0.000760\n",
      "epoch 547/1000   error=0.000757\n",
      "epoch 548/1000   error=0.000755\n",
      "epoch 549/1000   error=0.000753\n",
      "epoch 550/1000   error=0.000751\n",
      "epoch 551/1000   error=0.000748\n",
      "epoch 552/1000   error=0.000746\n",
      "epoch 553/1000   error=0.000744\n",
      "epoch 554/1000   error=0.000742\n",
      "epoch 555/1000   error=0.000739\n",
      "epoch 556/1000   error=0.000737\n",
      "epoch 557/1000   error=0.000735\n",
      "epoch 558/1000   error=0.000733\n",
      "epoch 559/1000   error=0.000731\n",
      "epoch 560/1000   error=0.000729\n",
      "epoch 561/1000   error=0.000726\n",
      "epoch 562/1000   error=0.000724\n",
      "epoch 563/1000   error=0.000722\n",
      "epoch 564/1000   error=0.000720\n",
      "epoch 565/1000   error=0.000718\n",
      "epoch 566/1000   error=0.000716\n",
      "epoch 567/1000   error=0.000714\n",
      "epoch 568/1000   error=0.000712\n",
      "epoch 569/1000   error=0.000710\n",
      "epoch 570/1000   error=0.000708\n",
      "epoch 571/1000   error=0.000706\n",
      "epoch 572/1000   error=0.000704\n",
      "epoch 573/1000   error=0.000702\n",
      "epoch 574/1000   error=0.000700\n",
      "epoch 575/1000   error=0.000698\n",
      "epoch 576/1000   error=0.000696\n",
      "epoch 577/1000   error=0.000694\n",
      "epoch 578/1000   error=0.000692\n",
      "epoch 579/1000   error=0.000690\n",
      "epoch 580/1000   error=0.000688\n",
      "epoch 581/1000   error=0.000686\n",
      "epoch 582/1000   error=0.000684\n",
      "epoch 583/1000   error=0.000682\n",
      "epoch 584/1000   error=0.000680\n",
      "epoch 585/1000   error=0.000678\n",
      "epoch 586/1000   error=0.000677\n",
      "epoch 587/1000   error=0.000675\n",
      "epoch 588/1000   error=0.000673\n",
      "epoch 589/1000   error=0.000671\n",
      "epoch 590/1000   error=0.000669\n",
      "epoch 591/1000   error=0.000667\n",
      "epoch 592/1000   error=0.000666\n",
      "epoch 593/1000   error=0.000664\n",
      "epoch 594/1000   error=0.000662\n",
      "epoch 595/1000   error=0.000660\n",
      "epoch 596/1000   error=0.000658\n",
      "epoch 597/1000   error=0.000657\n",
      "epoch 598/1000   error=0.000655\n",
      "epoch 599/1000   error=0.000653\n",
      "epoch 600/1000   error=0.000651\n",
      "epoch 601/1000   error=0.000650\n",
      "epoch 602/1000   error=0.000648\n",
      "epoch 603/1000   error=0.000646\n",
      "epoch 604/1000   error=0.000645\n",
      "epoch 605/1000   error=0.000643\n",
      "epoch 606/1000   error=0.000641\n",
      "epoch 607/1000   error=0.000639\n",
      "epoch 608/1000   error=0.000638\n",
      "epoch 609/1000   error=0.000636\n",
      "epoch 610/1000   error=0.000634\n",
      "epoch 611/1000   error=0.000633\n",
      "epoch 612/1000   error=0.000631\n",
      "epoch 613/1000   error=0.000630\n",
      "epoch 614/1000   error=0.000628\n",
      "epoch 615/1000   error=0.000626\n",
      "epoch 616/1000   error=0.000625\n",
      "epoch 617/1000   error=0.000623\n",
      "epoch 618/1000   error=0.000621\n",
      "epoch 619/1000   error=0.000620\n",
      "epoch 620/1000   error=0.000618\n",
      "epoch 621/1000   error=0.000617\n",
      "epoch 622/1000   error=0.000615\n",
      "epoch 623/1000   error=0.000614\n",
      "epoch 624/1000   error=0.000612\n",
      "epoch 625/1000   error=0.000611\n",
      "epoch 626/1000   error=0.000609\n",
      "epoch 627/1000   error=0.000607\n",
      "epoch 628/1000   error=0.000606\n",
      "epoch 629/1000   error=0.000604\n",
      "epoch 630/1000   error=0.000603\n",
      "epoch 631/1000   error=0.000601\n",
      "epoch 632/1000   error=0.000600\n",
      "epoch 633/1000   error=0.000598\n",
      "epoch 634/1000   error=0.000597\n",
      "epoch 635/1000   error=0.000596\n",
      "epoch 636/1000   error=0.000594\n",
      "epoch 637/1000   error=0.000593\n",
      "epoch 638/1000   error=0.000591\n",
      "epoch 639/1000   error=0.000590\n",
      "epoch 640/1000   error=0.000588\n",
      "epoch 641/1000   error=0.000587\n",
      "epoch 642/1000   error=0.000585\n",
      "epoch 643/1000   error=0.000584\n",
      "epoch 644/1000   error=0.000583\n",
      "epoch 645/1000   error=0.000581\n",
      "epoch 646/1000   error=0.000580\n",
      "epoch 647/1000   error=0.000578\n",
      "epoch 648/1000   error=0.000577\n",
      "epoch 649/1000   error=0.000576\n",
      "epoch 650/1000   error=0.000574\n",
      "epoch 651/1000   error=0.000573\n",
      "epoch 652/1000   error=0.000571\n",
      "epoch 653/1000   error=0.000570\n",
      "epoch 654/1000   error=0.000569\n",
      "epoch 655/1000   error=0.000567\n",
      "epoch 656/1000   error=0.000566\n",
      "epoch 657/1000   error=0.000565\n",
      "epoch 658/1000   error=0.000563\n",
      "epoch 659/1000   error=0.000562\n",
      "epoch 660/1000   error=0.000561\n",
      "epoch 661/1000   error=0.000560\n",
      "epoch 662/1000   error=0.000558\n",
      "epoch 663/1000   error=0.000557\n",
      "epoch 664/1000   error=0.000556\n",
      "epoch 665/1000   error=0.000554\n",
      "epoch 666/1000   error=0.000553\n",
      "epoch 667/1000   error=0.000552\n",
      "epoch 668/1000   error=0.000550\n",
      "epoch 669/1000   error=0.000549\n",
      "epoch 670/1000   error=0.000548\n",
      "epoch 671/1000   error=0.000547\n",
      "epoch 672/1000   error=0.000545\n",
      "epoch 673/1000   error=0.000544\n",
      "epoch 674/1000   error=0.000543\n",
      "epoch 675/1000   error=0.000542\n",
      "epoch 676/1000   error=0.000541\n",
      "epoch 677/1000   error=0.000539\n",
      "epoch 678/1000   error=0.000538\n",
      "epoch 679/1000   error=0.000537\n",
      "epoch 680/1000   error=0.000536\n",
      "epoch 681/1000   error=0.000534\n",
      "epoch 682/1000   error=0.000533\n",
      "epoch 683/1000   error=0.000532\n",
      "epoch 684/1000   error=0.000531\n",
      "epoch 685/1000   error=0.000530\n",
      "epoch 686/1000   error=0.000529\n",
      "epoch 687/1000   error=0.000527\n",
      "epoch 688/1000   error=0.000526\n",
      "epoch 689/1000   error=0.000525\n",
      "epoch 690/1000   error=0.000524\n",
      "epoch 691/1000   error=0.000523\n",
      "epoch 692/1000   error=0.000522\n",
      "epoch 693/1000   error=0.000520\n",
      "epoch 694/1000   error=0.000519\n",
      "epoch 695/1000   error=0.000518\n",
      "epoch 696/1000   error=0.000517\n",
      "epoch 697/1000   error=0.000516\n",
      "epoch 698/1000   error=0.000515\n",
      "epoch 699/1000   error=0.000514\n",
      "epoch 700/1000   error=0.000513\n",
      "epoch 701/1000   error=0.000511\n",
      "epoch 702/1000   error=0.000510\n",
      "epoch 703/1000   error=0.000509\n",
      "epoch 704/1000   error=0.000508\n",
      "epoch 705/1000   error=0.000507\n",
      "epoch 706/1000   error=0.000506\n",
      "epoch 707/1000   error=0.000505\n",
      "epoch 708/1000   error=0.000504\n",
      "epoch 709/1000   error=0.000503\n",
      "epoch 710/1000   error=0.000502\n",
      "epoch 711/1000   error=0.000501\n",
      "epoch 712/1000   error=0.000500\n",
      "epoch 713/1000   error=0.000499\n",
      "epoch 714/1000   error=0.000498\n",
      "epoch 715/1000   error=0.000496\n",
      "epoch 716/1000   error=0.000495\n",
      "epoch 717/1000   error=0.000494\n",
      "epoch 718/1000   error=0.000493\n",
      "epoch 719/1000   error=0.000492\n",
      "epoch 720/1000   error=0.000491\n",
      "epoch 721/1000   error=0.000490\n",
      "epoch 722/1000   error=0.000489\n",
      "epoch 723/1000   error=0.000488\n",
      "epoch 724/1000   error=0.000487\n",
      "epoch 725/1000   error=0.000486\n",
      "epoch 726/1000   error=0.000485\n",
      "epoch 727/1000   error=0.000484\n",
      "epoch 728/1000   error=0.000483\n",
      "epoch 729/1000   error=0.000482\n",
      "epoch 730/1000   error=0.000481\n",
      "epoch 731/1000   error=0.000480\n",
      "epoch 732/1000   error=0.000479\n",
      "epoch 733/1000   error=0.000478\n",
      "epoch 734/1000   error=0.000477\n",
      "epoch 735/1000   error=0.000476\n",
      "epoch 736/1000   error=0.000475\n",
      "epoch 737/1000   error=0.000474\n",
      "epoch 738/1000   error=0.000474\n",
      "epoch 739/1000   error=0.000473\n",
      "epoch 740/1000   error=0.000472\n",
      "epoch 741/1000   error=0.000471\n",
      "epoch 742/1000   error=0.000470\n",
      "epoch 743/1000   error=0.000469\n",
      "epoch 744/1000   error=0.000468\n",
      "epoch 745/1000   error=0.000467\n",
      "epoch 746/1000   error=0.000466\n",
      "epoch 747/1000   error=0.000465\n",
      "epoch 748/1000   error=0.000464\n",
      "epoch 749/1000   error=0.000463\n",
      "epoch 750/1000   error=0.000462\n",
      "epoch 751/1000   error=0.000461\n",
      "epoch 752/1000   error=0.000460\n",
      "epoch 753/1000   error=0.000460\n",
      "epoch 754/1000   error=0.000459\n",
      "epoch 755/1000   error=0.000458\n",
      "epoch 756/1000   error=0.000457\n",
      "epoch 757/1000   error=0.000456\n",
      "epoch 758/1000   error=0.000455\n",
      "epoch 759/1000   error=0.000454\n",
      "epoch 760/1000   error=0.000453\n",
      "epoch 761/1000   error=0.000452\n",
      "epoch 762/1000   error=0.000452\n",
      "epoch 763/1000   error=0.000451\n",
      "epoch 764/1000   error=0.000450\n",
      "epoch 765/1000   error=0.000449\n",
      "epoch 766/1000   error=0.000448\n",
      "epoch 767/1000   error=0.000447\n",
      "epoch 768/1000   error=0.000446\n",
      "epoch 769/1000   error=0.000446\n",
      "epoch 770/1000   error=0.000445\n",
      "epoch 771/1000   error=0.000444\n",
      "epoch 772/1000   error=0.000443\n",
      "epoch 773/1000   error=0.000442\n",
      "epoch 774/1000   error=0.000441\n",
      "epoch 775/1000   error=0.000441\n",
      "epoch 776/1000   error=0.000440\n",
      "epoch 777/1000   error=0.000439\n",
      "epoch 778/1000   error=0.000438\n",
      "epoch 779/1000   error=0.000437\n",
      "epoch 780/1000   error=0.000436\n",
      "epoch 781/1000   error=0.000436\n",
      "epoch 782/1000   error=0.000435\n",
      "epoch 783/1000   error=0.000434\n",
      "epoch 784/1000   error=0.000433\n",
      "epoch 785/1000   error=0.000432\n",
      "epoch 786/1000   error=0.000432\n",
      "epoch 787/1000   error=0.000431\n",
      "epoch 788/1000   error=0.000430\n",
      "epoch 789/1000   error=0.000429\n",
      "epoch 790/1000   error=0.000428\n",
      "epoch 791/1000   error=0.000428\n",
      "epoch 792/1000   error=0.000427\n",
      "epoch 793/1000   error=0.000426\n",
      "epoch 794/1000   error=0.000425\n",
      "epoch 795/1000   error=0.000424\n",
      "epoch 796/1000   error=0.000424\n",
      "epoch 797/1000   error=0.000423\n",
      "epoch 798/1000   error=0.000422\n",
      "epoch 799/1000   error=0.000421\n",
      "epoch 800/1000   error=0.000421\n",
      "epoch 801/1000   error=0.000420\n",
      "epoch 802/1000   error=0.000419\n",
      "epoch 803/1000   error=0.000418\n",
      "epoch 804/1000   error=0.000418\n",
      "epoch 805/1000   error=0.000417\n",
      "epoch 806/1000   error=0.000416\n",
      "epoch 807/1000   error=0.000415\n",
      "epoch 808/1000   error=0.000415\n",
      "epoch 809/1000   error=0.000414\n",
      "epoch 810/1000   error=0.000413\n",
      "epoch 811/1000   error=0.000412\n",
      "epoch 812/1000   error=0.000412\n",
      "epoch 813/1000   error=0.000411\n",
      "epoch 814/1000   error=0.000410\n",
      "epoch 815/1000   error=0.000409\n",
      "epoch 816/1000   error=0.000409\n",
      "epoch 817/1000   error=0.000408\n",
      "epoch 818/1000   error=0.000408\n",
      "epoch 819/1000   error=0.000406\n",
      "epoch 820/1000   error=0.000406\n",
      "epoch 821/1000   error=0.000405\n",
      "epoch 822/1000   error=0.000405\n",
      "epoch 823/1000   error=0.000404\n",
      "epoch 824/1000   error=0.000405\n",
      "epoch 825/1000   error=0.000403\n",
      "epoch 826/1000   error=0.000404\n",
      "epoch 827/1000   error=0.000403\n",
      "epoch 828/1000   error=0.000405\n",
      "epoch 829/1000   error=0.000403\n",
      "epoch 830/1000   error=0.000407\n",
      "epoch 831/1000   error=0.000406\n",
      "epoch 832/1000   error=0.000413\n",
      "epoch 833/1000   error=0.000412\n",
      "epoch 834/1000   error=0.000423\n",
      "epoch 835/1000   error=0.000425\n",
      "epoch 836/1000   error=0.000445\n",
      "epoch 837/1000   error=0.000452\n",
      "epoch 838/1000   error=0.000486\n",
      "epoch 839/1000   error=0.000506\n",
      "epoch 840/1000   error=0.000565\n",
      "epoch 841/1000   error=0.000609\n",
      "epoch 842/1000   error=0.000712\n",
      "epoch 843/1000   error=0.000805\n",
      "epoch 844/1000   error=0.000989\n",
      "epoch 845/1000   error=0.001173\n",
      "epoch 846/1000   error=0.001494\n",
      "epoch 847/1000   error=0.001841\n",
      "epoch 848/1000   error=0.002386\n",
      "epoch 849/1000   error=0.002995\n",
      "epoch 850/1000   error=0.003855\n",
      "epoch 851/1000   error=0.004814\n",
      "epoch 852/1000   error=0.006005\n",
      "epoch 853/1000   error=0.007281\n",
      "epoch 854/1000   error=0.008614\n",
      "epoch 855/1000   error=0.009948\n",
      "epoch 856/1000   error=0.011033\n",
      "epoch 857/1000   error=0.012061\n",
      "epoch 858/1000   error=0.012594\n",
      "epoch 859/1000   error=0.013136\n",
      "epoch 860/1000   error=0.013122\n",
      "epoch 861/1000   error=0.013244\n",
      "epoch 862/1000   error=0.012879\n",
      "epoch 863/1000   error=0.012737\n",
      "epoch 864/1000   error=0.012210\n",
      "epoch 865/1000   error=0.011929\n",
      "epoch 866/1000   error=0.011357\n",
      "epoch 867/1000   error=0.011012\n",
      "epoch 868/1000   error=0.010455\n",
      "epoch 869/1000   error=0.010089\n",
      "epoch 870/1000   error=0.009572\n",
      "epoch 871/1000   error=0.009205\n",
      "epoch 872/1000   error=0.008739\n",
      "epoch 873/1000   error=0.008382\n",
      "epoch 874/1000   error=0.007968\n",
      "epoch 875/1000   error=0.007627\n",
      "epoch 876/1000   error=0.007262\n",
      "epoch 877/1000   error=0.006939\n",
      "epoch 878/1000   error=0.006619\n",
      "epoch 879/1000   error=0.006317\n",
      "epoch 880/1000   error=0.006038\n",
      "epoch 881/1000   error=0.005755\n",
      "epoch 882/1000   error=0.005512\n",
      "epoch 883/1000   error=0.005249\n",
      "epoch 884/1000   error=0.005038\n",
      "epoch 885/1000   error=0.004793\n",
      "epoch 886/1000   error=0.004611\n",
      "epoch 887/1000   error=0.004384\n",
      "epoch 888/1000   error=0.004227\n",
      "epoch 889/1000   error=0.004016\n",
      "epoch 890/1000   error=0.003881\n",
      "epoch 891/1000   error=0.003686\n",
      "epoch 892/1000   error=0.003570\n",
      "epoch 893/1000   error=0.003390\n",
      "epoch 894/1000   error=0.003291\n",
      "epoch 895/1000   error=0.003123\n",
      "epoch 896/1000   error=0.003039\n",
      "epoch 897/1000   error=0.002884\n",
      "epoch 898/1000   error=0.002813\n",
      "epoch 899/1000   error=0.002669\n",
      "epoch 900/1000   error=0.002609\n",
      "epoch 901/1000   error=0.002475\n",
      "epoch 902/1000   error=0.002425\n",
      "epoch 903/1000   error=0.002301\n",
      "epoch 904/1000   error=0.002260\n",
      "epoch 905/1000   error=0.002145\n",
      "epoch 906/1000   error=0.002111\n",
      "epoch 907/1000   error=0.002004\n",
      "epoch 908/1000   error=0.001976\n",
      "epoch 909/1000   error=0.001876\n",
      "epoch 910/1000   error=0.001854\n",
      "epoch 911/1000   error=0.001762\n",
      "epoch 912/1000   error=0.001745\n",
      "epoch 913/1000   error=0.001658\n",
      "epoch 914/1000   error=0.001645\n",
      "epoch 915/1000   error=0.001564\n",
      "epoch 916/1000   error=0.001555\n",
      "epoch 917/1000   error=0.001480\n",
      "epoch 918/1000   error=0.001474\n",
      "epoch 919/1000   error=0.001403\n",
      "epoch 920/1000   error=0.001400\n",
      "epoch 921/1000   error=0.001334\n",
      "epoch 922/1000   error=0.001333\n",
      "epoch 923/1000   error=0.001271\n",
      "epoch 924/1000   error=0.001273\n",
      "epoch 925/1000   error=0.001214\n",
      "epoch 926/1000   error=0.001217\n",
      "epoch 927/1000   error=0.001162\n",
      "epoch 928/1000   error=0.001167\n",
      "epoch 929/1000   error=0.001115\n",
      "epoch 930/1000   error=0.001122\n",
      "epoch 931/1000   error=0.001072\n",
      "epoch 932/1000   error=0.001080\n",
      "epoch 933/1000   error=0.001033\n",
      "epoch 934/1000   error=0.001042\n",
      "epoch 935/1000   error=0.000997\n",
      "epoch 936/1000   error=0.001007\n",
      "epoch 937/1000   error=0.000965\n",
      "epoch 938/1000   error=0.000976\n",
      "epoch 939/1000   error=0.000936\n",
      "epoch 940/1000   error=0.000947\n",
      "epoch 941/1000   error=0.000909\n",
      "epoch 942/1000   error=0.000921\n",
      "epoch 943/1000   error=0.000884\n",
      "epoch 944/1000   error=0.000897\n",
      "epoch 945/1000   error=0.000862\n",
      "epoch 946/1000   error=0.000875\n",
      "epoch 947/1000   error=0.000842\n",
      "epoch 948/1000   error=0.000856\n",
      "epoch 949/1000   error=0.000823\n",
      "epoch 950/1000   error=0.000837\n",
      "epoch 951/1000   error=0.000806\n",
      "epoch 952/1000   error=0.000821\n",
      "epoch 953/1000   error=0.000791\n",
      "epoch 954/1000   error=0.000806\n",
      "epoch 955/1000   error=0.000777\n",
      "epoch 956/1000   error=0.000792\n",
      "epoch 957/1000   error=0.000765\n",
      "epoch 958/1000   error=0.000780\n",
      "epoch 959/1000   error=0.000753\n",
      "epoch 960/1000   error=0.000769\n",
      "epoch 961/1000   error=0.000743\n",
      "epoch 962/1000   error=0.000759\n",
      "epoch 963/1000   error=0.000734\n",
      "epoch 964/1000   error=0.000750\n",
      "epoch 965/1000   error=0.000726\n",
      "epoch 966/1000   error=0.000742\n",
      "epoch 967/1000   error=0.000719\n",
      "epoch 968/1000   error=0.000736\n",
      "epoch 969/1000   error=0.000712\n",
      "epoch 970/1000   error=0.000730\n",
      "epoch 971/1000   error=0.000707\n",
      "epoch 972/1000   error=0.000724\n",
      "epoch 973/1000   error=0.000702\n",
      "epoch 974/1000   error=0.000720\n",
      "epoch 975/1000   error=0.000699\n",
      "epoch 976/1000   error=0.000716\n",
      "epoch 977/1000   error=0.000696\n",
      "epoch 978/1000   error=0.000714\n",
      "epoch 979/1000   error=0.000693\n",
      "epoch 980/1000   error=0.000712\n",
      "epoch 981/1000   error=0.000692\n",
      "epoch 982/1000   error=0.000710\n",
      "epoch 983/1000   error=0.000691\n",
      "epoch 984/1000   error=0.000710\n",
      "epoch 985/1000   error=0.000690\n",
      "epoch 986/1000   error=0.000710\n",
      "epoch 987/1000   error=0.000691\n",
      "epoch 988/1000   error=0.000710\n",
      "epoch 989/1000   error=0.000692\n",
      "epoch 990/1000   error=0.000712\n",
      "epoch 991/1000   error=0.000694\n",
      "epoch 992/1000   error=0.000714\n",
      "epoch 993/1000   error=0.000696\n",
      "epoch 994/1000   error=0.000717\n",
      "epoch 995/1000   error=0.000699\n",
      "epoch 996/1000   error=0.000720\n",
      "epoch 997/1000   error=0.000703\n",
      "epoch 998/1000   error=0.000724\n",
      "epoch 999/1000   error=0.000707\n",
      "epoch 1000/1000   error=0.000729\n",
      "[array([[-0.01237466]]), array([[0.97208376]]), array([[0.97167736]]), array([[-0.04173082]])]\n"
     ]
    }
   ],
   "source": [
    "# Base class\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    # computes the output Y of a layer for a given input X\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # computes dE/dX for a given dE/dY (and update parameters if any)\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "# inherit from base class Layer\n",
    "class FCLayer(Layer):\n",
    "    # input_size = number of input neurons\n",
    "    # output_size = number of output neurons\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "        self.bias = np.random.rand(1, output_size) - 0.5\n",
    "\n",
    "    # returns output for a given input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    # computes dE/dW, dE/dB for a given output_error=dE/dY. Returns input_error=dE/dX.\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        \n",
    "        # print(f\"error.shape= {output_error.shape}\")\n",
    "        # print(f\"error= {output_error.shape}, W.T= {self.weights.T.shape}\")\n",
    "        # print(f\"x.T={self.input.T.shape}, error= {output_error.shape}\")\n",
    "       \n",
    "        \n",
    "        \n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        # dBias = output_error\n",
    "\n",
    "        # update parameters\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error\n",
    "    \n",
    "# inherit from base class Layer\n",
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    # returns the activated input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    # Returns input_error=dE/dX for a given output_error=dE/dY.\n",
    "    # learning_rate is not used because there is no \"learnable\" parameters.\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        return self.activation_prime(self.input) * output_error\n",
    "    \n",
    "# activation function and its derivative\n",
    "def tanh(x):\n",
    "    return np.tanh(x);\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1-np.tanh(x)**2;\n",
    "\n",
    "# loss function and its derivative\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true-y_pred, 2));\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2*(y_pred-y_true)/y_true.size;\n",
    "\n",
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "\n",
    "    # add layer to network\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    # set loss to use\n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "    # predict output for given input\n",
    "    def predict(self, input_data):\n",
    "        # sample dimension first\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "\n",
    "        # run network over all samples\n",
    "        for i in range(samples):\n",
    "            # forward propagation\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "\n",
    "    # train the network\n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "        # sample dimension first\n",
    "        samples = len(x_train)\n",
    "\n",
    "        # training loop\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                # forward propagation\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "\n",
    "                # compute loss (for display purpose only)\n",
    "                err += self.loss(y_train[j], output)\n",
    "\n",
    "                # backward propagation\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "\n",
    "            # calculate average error on all samples\n",
    "            err /= samples\n",
    "            print('epoch %d/%d   error=%f' % (i+1, epochs, err))\n",
    "            \n",
    "# training data\n",
    "x_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
    "y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
    "\n",
    "# x_train = dataloader[\"X_train\"].to_numpy().reshape((dataloader[\"X_train\"].shape[0],1,dataloader[\"X_train\"].shape[1]))\n",
    "# y_train = dataloader[\"Y_train\"].to_numpy().reshape((dataloader[\"Y_train\"].shape[0],1,dataloader[\"Y_train\"].shape[1]))\n",
    "\n",
    "# network\n",
    "net = Network()\n",
    "net.add(FCLayer(x_train.shape[2], 10))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.add(FCLayer(10, 1))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "\n",
    "# train\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(x_train, y_train, epochs=1000, learning_rate=0.1)\n",
    "\n",
    "# test\n",
    "out = net.predict(x_train)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bf1a466b-5b5b-47bf-a6a8-3d8f06ea7f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 2)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "896b00be-f6f2-47fb-87c4-30f08ac7fca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 1)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3759a9-93f6-4572-b736-1b212b056878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-course",
   "language": "python",
   "name": "ml-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
